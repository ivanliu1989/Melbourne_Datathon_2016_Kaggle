";trusted_connection=true;Port=1433;driver={SQL Server};TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
if(platform == "mac"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,";uid=",user,";pwd=",pass,
";Port=1433;driver=FreeTDS;TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
}
# rdp.csgplatform.com:5685
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
install.packages('RODBC')
install.packages("RODBC")
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
library(RODBC)
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
#load ODBC library
library(RODBC)
# #load data
# data <- sqlFetch(cn, 'myTable', colnames=FALSE, rows_at_time=1000)
# #load data
# data <- sqlQuery(cn, "select * from myTable")
# status <- sqlGetResults(cn, as.is = FALSE, errors = TRUE, max = 0, buffsize = 1000000,
#                         nullstring = NA_character_, na.strings = "NA", believeNRows = TRUE, dec = getOption("dec"),
#                         stringsAsFactors = default.stringsAsFactors())
# #read with odbcQuery
# status  <- odbcQuery(cn, "select * from myTable")
# data <- odbcFetchRows(cn, max = 0, buffsize = 10000, nullstring = NA_character_, believeNRows = TRUE)
# error <- odbcGetErrMsg(cn)
### function ###
connect <- function(host, db, user=NULL, pass=NULL, platform="win" ){
# TODO: Check input paramaters and add a branch for SQL auth on windows
if(platform == "win"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,
";trusted_connection=true;Port=1433;driver={SQL Server};TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
if(platform == "mac"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,";uid=",user,";pwd=",pass,
";Port=1433;driver=FreeTDS;TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
}
# rdp.csgplatform.com:5685
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
library(RODBC)
library(RODBC)
odbcDataSources()
connect <- function(host, db, user=NULL, pass=NULL, platform="win" ){
# TODO: Check input paramaters and add a branch for SQL auth on windows
if(platform == "win"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,
";trusted_connection=true;Port=1433;driver={SQL Server};TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
if(platform == "mac"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,";uid=",user,";pwd=",pass,
";Port=1433;driver=FreeTDS;TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
}
# rdp.csgplatform.com:5685
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
library(RODBC)
odbcDriverConnect()
odbcDataSources()
#load ODBC library
library(RODBC)
odbcDataSources()
# #load data
# data <- sqlFetch(cn, 'myTable', colnames=FALSE, rows_at_time=1000)
# #load data
# data <- sqlQuery(cn, "select * from myTable")
# status <- sqlGetResults(cn, as.is = FALSE, errors = TRUE, max = 0, buffsize = 1000000,
#                         nullstring = NA_character_, na.strings = "NA", believeNRows = TRUE, dec = getOption("dec"),
#                         stringsAsFactors = default.stringsAsFactors())
# #read with odbcQuery
# status  <- odbcQuery(cn, "select * from myTable")
# data <- odbcFetchRows(cn, max = 0, buffsize = 10000, nullstring = NA_character_, believeNRows = TRUE)
# error <- odbcGetErrMsg(cn)
### function ###
connect <- function(host, db, user=NULL, pass=NULL, platform="win" ){
# TODO: Check input paramaters and add a branch for SQL auth on windows
if(platform == "win"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,
";trusted_connection=true;Port=1433;driver={SQL Server};TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
if(platform == "mac"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,";uid=",user,";pwd=",pass,
";Port=1433;driver=FreeTDS;TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
}
# rdp.csgplatform.com:5685
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
#load ODBC library
library(RODBC)
odbcDataSources()
# #load data
# data <- sqlFetch(cn, 'myTable', colnames=FALSE, rows_at_time=1000)
# #load data
# data <- sqlQuery(cn, "select * from myTable")
# status <- sqlGetResults(cn, as.is = FALSE, errors = TRUE, max = 0, buffsize = 1000000,
#                         nullstring = NA_character_, na.strings = "NA", believeNRows = TRUE, dec = getOption("dec"),
#                         stringsAsFactors = default.stringsAsFactors())
# #read with odbcQuery
# status  <- odbcQuery(cn, "select * from myTable")
# data <- odbcFetchRows(cn, max = 0, buffsize = 10000, nullstring = NA_character_, believeNRows = TRUE)
# error <- odbcGetErrMsg(cn)
### function ###
connect <- function(host, db, user=NULL, pass=NULL, platform="win" ){
# TODO: Check input paramaters and add a branch for SQL auth on windows
if(platform == "win"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,
";trusted_connection=true;Port=1433;driver={SQL Server};TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
if(platform == "mac"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,";uid=",user,";pwd=",pass,
";Port=1433;driver=FreeTDS;TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
}
# rdp.csgplatform.com:5685
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
ch1 <- odbcConnect(dsn="sqlserver01", uid="sa", pwd="Servian1")
ch1 <- odbcConnect(dsn="sqlserver01", uid="sa", pwd="Servian1")
#load ODBC library
library(RODBC)
odbcDataSources()
ch1 <- odbcConnect(dsn="sqlserver01", uid="sa", pwd="Servian1")
# #load data
# data <- sqlFetch(cn, 'myTable', colnames=FALSE, rows_at_time=1000)
# #load data
# data <- sqlQuery(cn, "select * from myTable")
# status <- sqlGetResults(cn, as.is = FALSE, errors = TRUE, max = 0, buffsize = 1000000,
#                         nullstring = NA_character_, na.strings = "NA", believeNRows = TRUE, dec = getOption("dec"),
#                         stringsAsFactors = default.stringsAsFactors())
# #read with odbcQuery
# status  <- odbcQuery(cn, "select * from myTable")
# data <- odbcFetchRows(cn, max = 0, buffsize = 10000, nullstring = NA_character_, believeNRows = TRUE)
# error <- odbcGetErrMsg(cn)
### function ###
connect <- function(host, db, user=NULL, pass=NULL, platform="win" ){
# TODO: Check input paramaters and add a branch for SQL auth on windows
if(platform == "win"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,
";trusted_connection=true;Port=1433;driver={SQL Server};TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
if(platform == "mac"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,";uid=",user,";pwd=",pass,
";Port=1433;driver=FreeTDS;TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
}
# rdp.csgplatform.com:5685
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
ch1 <- odbcConnect(dsn="sqlserver01", uid="sa", pwd="Servian1")
require(Rserve)
Rserve()
Rserve()
install.packages(c("boot", "gtools", "manipulate"))
head(train)
rm(list = ls()); gc()
require(data.table);require(caret);require(doMC);require(ROCR)
registerDoMC(core=3)
load('data/new/cv_data_log_extend.RData')
install.packages("manipulate")
data("iris")
# this is a little tweak so that things line up nicely later on
iris$Species <- factor(iris$Species,
levels = c("versicolor","virginica","setosa"))
head(iris)
ound(cor(iris[,1:4]), 2)
round(cor(iris[,1:4]), 2)
pc <- princomp(iris[,1:4], cor=TRUE, scores=TRUE)
pc
summary(pc)
plot(pc,type="lines")
biplot(pc)
library(rgl)
plot3d(pc$scores[,1:3], col=iris$Species)
plot3d(pc$scores[,1:3], col=iris$Species)
plot3d(pc$scores[,1:3])#, col=iris$Species)
text3d(pc$scores[,1:3],texts=rownames(iris))
text3d(pc$loadings[,1:3], texts=rownames(pc$loadings), col="red")
coords <- NULL
for (i in 1:nrow(pc$loadings)) {
coords <- rbind(coords, rbind(c(0,0,0),pc$loadings[i,1:3]))
}
for (i in 1:nrow(pc$loadings)) {
coords <- rbind(coords, rbind(c(0,0,0),pc$loadings[i,1:3]))
}
lines3d(coords, col="red", lwd=4)
set.seed(42)
cl <- kmeans(iris[,1:4],3)
iris$cluster <- as.factor(cl$cluster)
plot3d(pc$scores[,1:3], col=iris$cluster, main="k-means clusters")
plot3d(pc$scores[,1:3], col=iris$Species, main="actual species")
with(iris, table(cluster, Species))
data("iris")
# this is a little tweak so that things line up nicely later on
iris$Species <- factor(iris$Species,
levels = c("versicolor","virginica","setosa"))
head(iris)
round(cor(iris[,1:4]), 2)
pc <- princomp(iris[,1:4], cor=TRUE, scores=TRUE)
summary(pc)
plot(pc,type="lines")
biplot(pc)
library(rgl)
plot3d(pc$scores[,1:3], col=iris$Species)
text3d(pc$scores[,1:3],texts=rownames(iris))
text3d(pc$loadings[,1:3], texts=rownames(pc$loadings), col="red")
coords <- NULL
for (i in 1:nrow(pc$loadings)) {
coords <- rbind(coords, rbind(c(0,0,0),pc$loadings[i,1:3]))
}
lines3d(coords, col="red", lwd=4)
set.seed(42)
cl <- kmeans(iris[,1:4],3)
iris$cluster <- as.factor(cl$cluster)
plot3d(pc$scores[,1:3], col=iris$cluster, main="k-means clusters")
A <- matrix(c(1,2,3,4),nrow = 2, byrow = T)
B <- matrix(c(3,4,5,6),nrow = 2, byrow = T)
a <- c(1,2)
b <- c(2,3)
diag(10)
A
B
A*B
A%*%B
A%o%B # AB' A%*%t(B)
crossprod(A,B) # A'B  t(A)%*%A
crossprod(A) # A'A
b
solve(A,b) # A%*%solve(A,b)
solve(A,a) # A%*%solve(A,b)
a <- c(1200:1300)
a
b <- seq(15,100,5)
b
a/b
c <- a/b
c
a/15
apply(b, f(x) a/x)
apply(b, f(x){a/x})
sapply(b, f(x){a/x})
sapply(b, f(x){a/x})
lapply(b, f(x){a/x})
lapply(b, f(x)a/x)
lapply(b, f(x) a/x)
lapply(b,
f(x){
a/x
}
)
?sapply
b
sapply(b, a/x)
sapply(b, mean)
sapply(b, function(x) a/x)
a
x <âˆ’ c ( 9 : 2 0 , 1 : 5 , 3 : 7 , 0 : 8 )
x <- c( 9 : 2 0 , 1 : 5 , 3 : 7 , 0 : 8 )
x <- c(9:20,1:5,3:7,0:8)
x
(xu<-x[!duplicated(x)])
unique ( x ) # i s more e f f i c i e n t
x[!duplicated(x)]
gc()
setwd('/Users/ivanliu/Downloads/datathon2016/Melbourne_Datathon_2016_Kaggle')
rm(list=ls());gc()
load('../data/model/total.RData')
total$id <- 1:nrow(total)
order_id <- total$id
#########################
### 1.geo information ###
#########################
geo_info <- read.delim('../data_new/AU.txt',header = FALSE,na.strings = "",stringsAsFactors=FALSE)
names(geo_info) <- c('geonameid','name','asciiname','alternatenames','latitude','longitude',
'feature_class','feature_code','country_code','cc2','admin1_code',
'admin2_code','admin3_code','admin4_code','population','elevation',
'dem','timezone','modification_date')
geo_info_postal <- read.delim('../data_new/AU_postal.txt',header = FALSE,na.strings = "",stringsAsFactors=FALSE)
names(geo_info_postal) <- c('country_code','postal_code','place_name','admin_name1','admin_code1',
'admin_name2','admin_code2','admin_name3','admin_code3','latitude','longitude','accuracy')
head(geo_info);head(geo_info_postal)
geo_info <- geo_info[,c('geonameid','name','latitude','longitude','feature_class','feature_code','population','dem','timezone','admin1_code')]
geo_info_postal <- geo_info_postal[,c('country_code','postal_code','place_name')]
geo_info$name <- tolower(geo_info$name)
geo_info_postal$place_name <- tolower(geo_info_postal$place_name)
geo_info_postal$geonameid2 <- paste0(geo_info_postal$country_code,'-',
ifelse(geo_info_postal$postal_code < 100, paste0('00', geo_info_postal$postal_code), ifelse(geo_info_postal$postal_code < 1000, paste0('0',geo_info_postal$postal_code),geo_info_postal$postal_code))
,'-',geo_info_postal$place_name)
geo_info_postal$geonameid2 <- gsub(" ", "-", geo_info_postal$geonameid2)
geo_total <- merge(geo_info_postal, geo_info, by.x = 'place_name', by.y = 'name', all.x = T, all.y = T, sort = F)
geo_total_id <- geo_total[!duplicated(geo_total$geonameid),c('geonameid','feature_class','feature_code')]
geo_total_post <- geo_total[!duplicated(geo_total$geonameid2),c('geonameid2','feature_class','feature_code')]
# save(geo_total_id, geo_total_post, file='../data_new/geo_total_info.RData')
# load('../data_new/geo_total_info.RData')
######################
### 2.job geo list ###
######################
total_geo <- total[,c('job_id', 'location_id')]; #rm(total)
total_geo$location_id_2 <- gsub("g_id:", "", total_geo$location_id)
total_geo$location_id_2 <- gsub("g_zip:", "", total_geo$location_id_2)
head(total_geo)
###############
### 3.merge ###
###############
total_geo$location_id_2 <- tolower(total_geo$location_id_2); total_geo$location_id <- NULL
geo_total$geonameid <- tolower(geo_total$geonameid); geo_total$geonameid2 <- tolower(geo_total$geonameid2)
head(total_geo); head(geo_total)
total_geo_merge <- merge(total_geo, geo_total_id, by.x = 'location_id_2', by.y = 'geonameid', all.x = T)
total_geo_merge2 <- merge(total_geo, geo_total_post, by.x = 'location_id_2', by.y = 'geonameid2', all.x = T)
dim(total_geo);dim(total_geo_merge);dim(total_geo_merge2)
total_geo_id <- total_geo_merge[!is.na(total_geo_merge$feature_class), ]
total_geo_post <- total_geo_merge2[!is.na(total_geo_merge2$feature_class), ]
dim(total_geo_id);dim(total_geo_post)
total_geo_all <- rbind(total_geo_post, total_geo_id)
# total_geo_all[total_geo_all$job_id %in% total_geo_all[duplicated(total_geo_all$job_id),'job_id'],]
total_geo_all <- total_geo_all[!duplicated(total_geo_all$job_id),] # 1. total
# bug fix
total_geo_all
missed_loc <- total[!total$job_id %in% unique(total_geo_all$job_id), c('job_id','location_id')]
# write.csv(missed_loc, file = './missed_loc.csv')
missed_loc <- read.csv('./missed_loc.csv', header = T, stringsAsFactors = F)
missed_g_zip <- missed_loc[missed_loc$Identify == 0, ]
missed_other <- missed_loc[missed_loc$Identify == 1, ]
missed_g_id <- missed_other[missed_other$location_id != 'a_id:AU',]
missed_a_id <- missed_other[missed_other$location_id == 'a_id:AU',]
missed_g_zip$name <- gsub("-", " ", missed_g_zip$Location_name)
missed_g_zip <- merge(missed_g_zip, geo_info, by = 'name', all.x = T)
missed_g_zip <- missed_g_zip[!duplicated(missed_g_zip$job_id), c('job_id', 'feature_class', 'feature_code')] # 2. missed 1
head(total[total$job_id %in% missed_g_id$job_id,'raw_location'])
missed_g_id$feature_class <- 'gid_NA'
missed_g_id$feature_code <- 'gid_NA'
missed_g_id <- missed_g_id[, c('job_id', 'feature_class', 'feature_code')] # 3. missed 2
head(missed_a_id)
head(total[total$job_id %in% missed_a_id$job_id,'raw_location'])
missed_a_id$feature_class <- 'gid_NA'
missed_a_id$feature_code <- 'gid_NA'
missed_a_id <- missed_a_id[, c('job_id', 'feature_class', 'feature_code')] # 3. missed 3
# combine
geo_infor_total <- rbind(total_geo_all[,2:4], missed_g_zip,missed_a_id, missed_g_id)
geo_infor_total <- geo_infor_total[!duplicated(geo_infor_total$job_id),]
geo_infor_total <- merge(total[,c('job_id','hat','id')], geo_infor_total, by = 'job_id', all.x = T, all.y = F, sort = F)
geo_infor_total <- geo_infor_total[order(match(geo_infor_total[,'id'],order_id)),]
identical(geo_infor_total$job_id,total$job_id)
geo_infor_total[is.na(geo_infor_total$feature_class),3] <- 'gid_NA'
geo_infor_total[is.na(geo_infor_total$feature_code),4] <- 'gid_NA'
geo_infor_total$feature_class <- as.factor(geo_infor_total$feature_class)
geo_infor_total$feature_code <- as.factor(geo_infor_total$feature_code)
library(caret)
head(geo_infor_total)
head(geo_infor_total[,-3])
dummies <- dummyVars(hat ~ ., data = geo_infor_total[,-3], sep = "_", levelsOnly = FALSE, fullRank = TRUE)
geo_info_dummy <- predict(dummies, newdata = geo_infor_total)
geo_info_dummy[is.na(geo_info_dummy)] <- 0
head(geo_info_dummy)
names(geo_info_dummy)
colnames(geo_info_dummy)
geo_info_dummy <- geo_info_dummy[,-c(2,21)] # check
identical(total$job_id,geo_info_dummy[,'job_id'])
geo_info_dummy[,'job_id']
total$job_id-geo_info_dummy[,'job_id']
sum(total$job_id-geo_info_dummy[,'job_id'])
save(geo_info_dummy, file='../data_new/geo_info_dummy.RData')
names(geo_info_dummy)
colnames(geo_info_dummy)
head(geo_info_dummy[,2:61])
setwd('/Users/ivanliu/Downloads/datathon2016/Melbourne_Datathon_2016_Kaggle')
rm(list=ls());gc()
library(Matrix)
load('../data/model/total.RData')
source('./rscripts/a.preprocess_func.R')
load('../data_new/model_features_20160430.RData')
title_key_words_cnt <- rowSums(dtm_title >0)
abs_key_words_cnt <- rowSums(dtm_abstract >0)
type_key_words_cnt <- rowSums(dtm_job_type >0)
loc_key_words_cnt <- rowSums(dtm_location >0)
salary_type <- ifelse(total$salary_type == 'h', 0, 1)
salary_type[is.na(salary_type)] <- 1
load('../data_new/avg_salary.RData')
feat_list <- c()
for(c in unique(total$class_id)[!is.na(unique(total$class_id))]){
feat_name <- paste0('min_salary_ratio_',c)
total[,feat_name] <- total[,'salary_min'] / avg_salary[avg_salary$class_id == c,'min_salary']
total[is.na(total[,feat_name]),feat_name] <- 1
feat_list <- c(feat_list, feat_name)
}
for(c in unique(total$class_id)[!is.na(unique(total$class_id))]){
feat_name <- paste0('max_salary_ratio_',c)
total[,feat_name] <- total[,'salary_max'] / avg_salary[avg_salary$class_id == c,'max_salary']
total[is.na(total[,feat_name]),feat_name] <- 1
feat_list <- c(feat_list, feat_name)
}
for(c in unique(total$class_id)[!is.na(unique(total$class_id))]){
feat_name <- paste0('var_salary_ratio_',c)
total[,feat_name] <- (total[,'salary_max'] - total[,'salary_min']) / avg_salary[avg_salary$class_id == c,'var_salary']
total[is.na(total[,feat_name]),feat_name] <- 1
feat_list <- c(feat_list, feat_name)
}
salary_features <- total[,feat_list]
load('../data_new/user_click_freq_pct.RData')
load('../data_new/tgt_impr_cnt_pct.RData')
tgt_impr_all_cnt <- rowSums(tgt_impr_cnt[,4:33] > 0)
tgt_user_click_cnt <- rowSums(tgt_user_click[,4:33] > 0)
load('../data_new/geo_info_dummy.RData')
head(geo_info_dummy[,2:61])
load('../data_new/h.key_words_counts.RData')
rm_feat <- colSums(dtm_title[total[,'hat']==-1,])
dtm_title <- dtm_title[,rm_feat!=0]
rm_feat <- colSums(dtm_abstract[total[,'hat']==-1,])
dtm_abstract <- dtm_abstract[,rm_feat!=0]
rm_feat <- colSums(dtm_job_type[total[,'hat']==-1,])
dtm_job_type <- dtm_job_type[,rm_feat!=0]
rm_feat <- colSums(dtm_location[total[,'hat']==-1,])
dtm_location <- dtm_location[,rm_feat!=0]
pt3 <- as.matrix(cbind(salary_type = salary_type,
salary_features,
tgt_impr_cnt[,4:33],
tgt_impr_all_cnt = tgt_impr_all_cnt,
tgt_user_click[,4:33],
tgt_user_click_cnt = tgt_user_click_cnt,
title_key_words_cnt = title_key_words_cnt,
abs_key_words_cnt = abs_key_words_cnt,
type_key_words_cnt = type_key_words_cnt,
loc_key_words_cnt = loc_key_words_cnt,
geo_info_dummy[,2:61],
obj_hat = total$hat))
dim(pt3)
head(pt3)
all <- cbind(job_id = total$job_id,
dtm_title,
dtm_abstract,
dtm_job_type,
dtm_location,
# dtm_all,
pt3
)
train <- all[all[,'obj_hat'] != -1, ]
test <- all[all[,'obj_hat'] == -1, ]
save(train,test, file ='../data_new/model_unigram_idf_final_20160430.RData')
dim(train)
tail(colnames(train))
