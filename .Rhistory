c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,";uid=",user,";pwd=",pass,
";Port=1433;driver=FreeTDS;TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
}
# rdp.csgplatform.com:5685
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
#load ODBC library
library(RODBC)
odbcDataSources()
# #load data
# data <- sqlFetch(cn, 'myTable', colnames=FALSE, rows_at_time=1000)
# #load data
# data <- sqlQuery(cn, "select * from myTable")
# status <- sqlGetResults(cn, as.is = FALSE, errors = TRUE, max = 0, buffsize = 1000000,
#                         nullstring = NA_character_, na.strings = "NA", believeNRows = TRUE, dec = getOption("dec"),
#                         stringsAsFactors = default.stringsAsFactors())
# #read with odbcQuery
# status  <- odbcQuery(cn, "select * from myTable")
# data <- odbcFetchRows(cn, max = 0, buffsize = 10000, nullstring = NA_character_, believeNRows = TRUE)
# error <- odbcGetErrMsg(cn)
### function ###
connect <- function(host, db, user=NULL, pass=NULL, platform="win" ){
# TODO: Check input paramaters and add a branch for SQL auth on windows
if(platform == "win"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,
";trusted_connection=true;Port=1433;driver={SQL Server};TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
if(platform == "mac"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,";uid=",user,";pwd=",pass,
";Port=1433;driver=FreeTDS;TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
}
# rdp.csgplatform.com:5685
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
ch1 <- odbcConnect(dsn="sqlserver01", uid="sa", pwd="Servian1")
ch1 <- odbcConnect(dsn="sqlserver01", uid="sa", pwd="Servian1")
#load ODBC library
library(RODBC)
odbcDataSources()
ch1 <- odbcConnect(dsn="sqlserver01", uid="sa", pwd="Servian1")
# #load data
# data <- sqlFetch(cn, 'myTable', colnames=FALSE, rows_at_time=1000)
# #load data
# data <- sqlQuery(cn, "select * from myTable")
# status <- sqlGetResults(cn, as.is = FALSE, errors = TRUE, max = 0, buffsize = 1000000,
#                         nullstring = NA_character_, na.strings = "NA", believeNRows = TRUE, dec = getOption("dec"),
#                         stringsAsFactors = default.stringsAsFactors())
# #read with odbcQuery
# status  <- odbcQuery(cn, "select * from myTable")
# data <- odbcFetchRows(cn, max = 0, buffsize = 10000, nullstring = NA_character_, believeNRows = TRUE)
# error <- odbcGetErrMsg(cn)
### function ###
connect <- function(host, db, user=NULL, pass=NULL, platform="win" ){
# TODO: Check input paramaters and add a branch for SQL auth on windows
if(platform == "win"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,
";trusted_connection=true;Port=1433;driver={SQL Server};TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
if(platform == "mac"){
c <- odbcDriverConnect(connection=paste0("server=",host,";database=",db,";uid=",user,";pwd=",pass,
";Port=1433;driver=FreeTDS;TDS_Version=7.0;"))
if(class(c) == 'RODBC'){
writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
}
# rdp.csgplatform.com:5685
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
ch1 <- odbcConnect(dsn="sqlserver01", uid="sa", pwd="Servian1")
require(Rserve)
Rserve()
Rserve()
install.packages(c("boot", "gtools", "manipulate"))
head(train)
rm(list = ls()); gc()
require(data.table);require(caret);require(doMC);require(ROCR)
registerDoMC(core=3)
load('data/new/cv_data_log_extend.RData')
install.packages("manipulate")
data("iris")
# this is a little tweak so that things line up nicely later on
iris$Species <- factor(iris$Species,
levels = c("versicolor","virginica","setosa"))
head(iris)
ound(cor(iris[,1:4]), 2)
round(cor(iris[,1:4]), 2)
pc <- princomp(iris[,1:4], cor=TRUE, scores=TRUE)
pc
summary(pc)
plot(pc,type="lines")
biplot(pc)
library(rgl)
plot3d(pc$scores[,1:3], col=iris$Species)
plot3d(pc$scores[,1:3], col=iris$Species)
plot3d(pc$scores[,1:3])#, col=iris$Species)
text3d(pc$scores[,1:3],texts=rownames(iris))
text3d(pc$loadings[,1:3], texts=rownames(pc$loadings), col="red")
coords <- NULL
for (i in 1:nrow(pc$loadings)) {
coords <- rbind(coords, rbind(c(0,0,0),pc$loadings[i,1:3]))
}
for (i in 1:nrow(pc$loadings)) {
coords <- rbind(coords, rbind(c(0,0,0),pc$loadings[i,1:3]))
}
lines3d(coords, col="red", lwd=4)
set.seed(42)
cl <- kmeans(iris[,1:4],3)
iris$cluster <- as.factor(cl$cluster)
plot3d(pc$scores[,1:3], col=iris$cluster, main="k-means clusters")
plot3d(pc$scores[,1:3], col=iris$Species, main="actual species")
with(iris, table(cluster, Species))
data("iris")
# this is a little tweak so that things line up nicely later on
iris$Species <- factor(iris$Species,
levels = c("versicolor","virginica","setosa"))
head(iris)
round(cor(iris[,1:4]), 2)
pc <- princomp(iris[,1:4], cor=TRUE, scores=TRUE)
summary(pc)
plot(pc,type="lines")
biplot(pc)
library(rgl)
plot3d(pc$scores[,1:3], col=iris$Species)
text3d(pc$scores[,1:3],texts=rownames(iris))
text3d(pc$loadings[,1:3], texts=rownames(pc$loadings), col="red")
coords <- NULL
for (i in 1:nrow(pc$loadings)) {
coords <- rbind(coords, rbind(c(0,0,0),pc$loadings[i,1:3]))
}
lines3d(coords, col="red", lwd=4)
set.seed(42)
cl <- kmeans(iris[,1:4],3)
iris$cluster <- as.factor(cl$cluster)
plot3d(pc$scores[,1:3], col=iris$cluster, main="k-means clusters")
A <- matrix(c(1,2,3,4),nrow = 2, byrow = T)
B <- matrix(c(3,4,5,6),nrow = 2, byrow = T)
a <- c(1,2)
b <- c(2,3)
diag(10)
A
B
A*B
A%*%B
A%o%B # AB' A%*%t(B)
crossprod(A,B) # A'B  t(A)%*%A
crossprod(A) # A'A
b
solve(A,b) # A%*%solve(A,b)
solve(A,a) # A%*%solve(A,b)
a <- c(1200:1300)
a
b <- seq(15,100,5)
b
a/b
c <- a/b
c
a/15
apply(b, f(x) a/x)
apply(b, f(x){a/x})
sapply(b, f(x){a/x})
sapply(b, f(x){a/x})
lapply(b, f(x){a/x})
lapply(b, f(x)a/x)
lapply(b, f(x) a/x)
lapply(b,
f(x){
a/x
}
)
?sapply
b
sapply(b, a/x)
sapply(b, mean)
sapply(b, function(x) a/x)
a
x <âˆ’ c ( 9 : 2 0 , 1 : 5 , 3 : 7 , 0 : 8 )
x <- c( 9 : 2 0 , 1 : 5 , 3 : 7 , 0 : 8 )
x <- c(9:20,1:5,3:7,0:8)
x
(xu<-x[!duplicated(x)])
unique ( x ) # i s more e f f i c i e n t
x[!duplicated(x)]
gc()
?setdiff
(x <- c(sort(sample(1:20, 9)), NA))
(y <- c(sort(sample(3:23, 7)), NA))
union(x, y)
intersect(x, y)
setdiff(y, x)
setequal(x, y)
library(xgboost)
?xgb.train
setwd('/Users/ivanliu/Downloads/datathon2016/Melbourne_Datathon_2016_Kaggle')
rm(list=ls());gc()
load('../data/model/total.RData')
pred_a <- a
pred_a$hat <- pred_a$hat >=0.5
pred_a$hat2 <- b$hat >= 0.5
pred_a$vari <- pred_a$hat == pred_a$hat2
total[total$job_id %in% pred_a[!pred_a$vari, 'job_id'],]
setwd('/Users/ivanliu/Downloads/datathon2016/Melbourne_Datathon_2016_Kaggle')
rm(list=ls());gc()
load('../data/model/total.RData')
pred_a <- a
a <- read.csv('../pred/submissions_20160502_bigram_full_idf_salary_geo.csv')
b <- read.csv('../pred/submit_20160505_0.1_fix2_0.989216.csv')
pred_a <- a
pred_a$hat <- pred_a$hat >=0.5
pred_a$hat2 <- b$hat >= 0.5
pred_a$vari <- pred_a$hat == pred_a$hat2
total[total$job_id %in% pred_a[!pred_a$vari, 'job_id'],]
a[a$job_id==1301359,]
a[a$job_id==1301928,]
b[b$job_id==1301928,]
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend.csv')
pred_a <- a
pred_a$hat <- pred_a$hat >=0.5
pred <- a
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend.csv')
pred <- a
pred$hat <- 0.5 * a$hat + 0.5 * b$hat
cor(a$hat,b$hat)
head(a)
head(b)
pred_a <- a
pred_a$hat <- pred_a$hat >=0.5
pred_a$hat2 <- b$hat >= 0.5
pred_a$vari <- pred_a$hat == pred_a$hat2
table(pred_a$vari)
hist(a$hat)
hist(b$hat)
hist(log(a$hat))
hist(log(b$hat))
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend.csv')
pred <- a
pred$hat <- 0.5 * a$hat + 0.5 * b$hat
write.csv(pred, file = '../pred/noah_ivan_0.5_0.5.csv', row.names = F)
identical(a$job_id,b$job_id)
head(a$job_id)
head(b$job_id)
length(unique(a$job_id))
length(unique(b$job_id))
dim(a)
merge(a
, b
, by = "job_id"
, sort = F)
df.a.b.merge <- merge(a
, b
, by = "job_id"
, sort = F)
cor(df.a.b.merge$hat.x, df.a.b.merge$hat.y)
pred$hat <- 0.5 * df.a.b.merge$hat.x + 0.5 * df.a.b.merge$hat.y
pred <- df.a.b.merge$job_id
write.csv(pred, file = '../pred_final/noah_ivan_0.5_0.5.csv', row.names = F)
pred
head(pred)
job_id <- df.a.b.merge$job_id
hat <- 0.5 * df.a.b.merge$hat.x + 0.5 * df.a.b.merge$hat.y
submit <- data.table(job_id = job_id, hat = hat)
require(data.table)
submit <- data.table(job_id = job_id, hat = hat)
submit
write.csv(pred, file = '../pred_final/noah_ivan_0.5_0.5.csv', row.names = F)
head(a)
write.csv(pred, file = '../pred_final/noah_ivan_0.5_0.5.csv', row.names = F, col.names = T, quote = F)
write.csv(submit, file = '../pred_final/noah_ivan_0.5_0.5.csv', row.names = F, col.names = T, quote = F)
write.csv(submit, file = '../pred_final/noah_ivan_0.5_0.5.csv', row.names = F, quote = F)
setwd('/Users/ivanliu/Downloads/datathon2016/Melbourne_Datathon_2016_Kaggle')
rm(list=ls());gc()
load('../data/model/total.RData')
load('../model_bigram_idf_scale_full_fix.RData')
library(xgboost)
library(caret)
library(Matrix)
library(caTools)
head(train[,extra_feature])
colnames(train[,extra_feature])
setwd('/Users/ivanliu/Downloads/datathon2016/Melbourne_Datathon_2016_Kaggle')
rm(list=ls());gc()
a <- read.csv('../pred/submissions_20160501_unigram_full_idf_salary_geo.csv')
b <- read.csv('../pred/submissions_20160502_bigram_full_idf_salary_geo.csv')
c <- read.csv('../pred/submissions_20160505_0.986796.csv')
d <- read.csv('../pred/submissions_20160505_0.987314.csv')
e <- read.csv('../pred/submit_20160505_0.1_fix2_0.986502.csv')
f <- read.csv('../pred/submit_20160505_0.1_fix2_0.989216.csv')
g <- read.csv('../pred/submit_20160505_0.2_fix2_0.986292.csv')
pred <- a
pred$hat <- 0.2 * a$hat +
0.8/6 * b$hat +
0.8/6 * c$hat +
0.8/6 * d$hat +
0.8/6 * e$hat +
0.8/6 * f$hat +
0.8/6 * g$hat
head(pred)
pred_a <- a
cor(a$hat,pred$hat)
write.csv(pred, file = '../submit_20160505_blend_7_models.csv', row.names = F)
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend_7_models.csv')
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend_7_models.csv')
df.a.b.merge <- merge(a
, b
, by = "job_id"
, sort = F)
cor(df.a.b.merge$hat.x, df.a.b.merge$hat.y)
job_id <- df.a.b.merge$job_id
hat <- 0.5 * df.a.b.merge$hat.x + 0.5 * df.a.b.merge$hat.y
submit <- data.table(job_id = job_id, hat = hat)
write.csv(submit, file = '../pred_final/noah_ivan_0.5_0.5_2.csv', row.names = F, quote = F)
### NI
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend_7_models.csv')
df.a.b.merge <- merge(a
, b
, by = "job_id"
, sort = F)
cor(df.a.b.merge$hat.x, df.a.b.merge$hat.y)
job_id <- df.a.b.merge$job_id
hat <- 0.3 * df.a.b.merge$hat.x + 0.7 * df.a.b.merge$hat.y
submit <- data.table(job_id = job_id, hat = hat)
write.csv(submit, file = '../pred_final/noah_ivan_0.3_0.7_2.csv', row.names = F, quote = F)
# 0.98991, 3:7
###
### NI
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend_7_models.csv')
df.a.b.merge <- merge(a
, b
, by = "job_id"
, sort = F)
cor(df.a.b.merge$hat.x, df.a.b.merge$hat.y)
job_id <- df.a.b.merge$job_id
hat <- 0.4 * df.a.b.merge$hat.x + 0.6 * df.a.b.merge$hat.y
submit <- data.table(job_id = job_id, hat = hat)
write.csv(submit, file = '../pred_final/noah_ivan_0.4_0.6_2.csv', row.names = F, quote = F)
# 0.98991, 3:7
###
### NI
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend_7_models.csv')
df.a.b.merge <- merge(a
, b
, by = "job_id"
, sort = F)
cor(df.a.b.merge$hat.x, df.a.b.merge$hat.y)
job_id <- df.a.b.merge$job_id
hat <- 0.6 * df.a.b.merge$hat.x + 0.4 * df.a.b.merge$hat.y
submit <- data.table(job_id = job_id, hat = hat)
write.csv(submit, file = '../pred_final/noah_ivan_0.6_0.4_2.csv', row.names = F, quote = F)
# 0.98991, 3:7
###
head(df.a.b.merge)
df.a.b.merge$IVAN <- df.a.b.merge$hat.y >= 0.5
df.a.b.merge$NOAH <- df.a.b.merge$hat.x >= 0.5
df.a.b.merge$DIFF <- df.a.b.merge$IVAN == df.a.b.merge$NOAH
table(df.a.b.merge$DIFF)
diff <- df.a.b.merge$DIFF[!df.a.b.merge$DIFF, ]
diff <- df.a.b.merge[!df.a.b.merge$DIFF, ]
head(diff)
load('../data/model/total.RData')
total[total$job_id == 442830, 'abstract']
head(total[totol$hat == 1, 'class_description'])
head(total[total$hat == 1, 'class_description'])
total[total$job_id == 14382, 'abstract']
total[total$job_id == 638416, 'abstract']
total[total$job_id == 174394, 'abstract']
total[total$job_id == 174394, c('job_title','abstract')]
total[total$job_id == 174394, c('title','abstract')]
total[total$job_id == 175687, c('title','abstract')]
total[total$job_id == 623245, c('title','abstract')]
### NI
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend_7_models.csv')
df.a.b.merge <- merge(a
, b
, by = "job_id"
, sort = F)
cor(df.a.b.merge$hat.x, df.a.b.merge$hat.y)
job_id <- df.a.b.merge$job_id
hat <- 0.7 * df.a.b.merge$hat.x + 0.3 * df.a.b.merge$hat.y
submit <- data.table(job_id = job_id, hat = hat)
write.csv(submit, file = '../pred_final/noah_ivan_0.7_0.3_2.csv', row.names = F, quote = F)
# 0.98991, 3:7
###
submit
head(diff, 20)[11:20]
head(diff, 20)[11:20,]
total[total$job_id %in% head(diff, 20)[11:20,1], c('title','abstract')]
head(diff, 20)[11:20,]
total[total$job_id %in% head(diff, 20)[11:20,1], c('job_id','title','abstract')]
setwd('/Users/ivanliu/Downloads/datathon2016/Melbourne_Datathon_2016_Kaggle')
rm(list=ls());gc()
load('../data/model/total.RData')
require(data.table)
a <- read.csv('../pred/submissions_20160501_unigram_full_idf_salary_geo.csv')
b <- read.csv('../pred/submissions_20160502_bigram_full_idf_salary_geo.csv')
c <- read.csv('../pred/submissions_20160505_0.986796.csv')
d <- read.csv('../pred/submissions_20160505_0.987314.csv')
e <- read.csv('../pred/submit_20160505_0.1_fix2_0.986502.csv')
f <- read.csv('../pred/submit_20160505_0.1_fix2_0.989216.csv')
g <- read.csv('../pred/submit_20160505_0.2_fix2_0.986292.csv')
h <- read.csv('../pred/submit_20160505_0.2_bytree_3.40pm.csv')
0.7/6
pred <- a
pred$hat <- 0.15 * a$hat +
0.7/6 * b$hat +
0.7/6 * c$hat +
0.7/6 * d$hat +
0.7/6 * e$hat +
0.7/6 * f$hat +
0.7/6 * g$hat +
0.15 * h$hat
cor(a$hat,pred$hat)
cor(h$hat,pred$hat)
write.csv(pred, file = '../submit_20160505_blend_8_models.csv', row.names = F)
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend_8_models.csv')
df.a.b.merge <- merge(a
, b
, by = "job_id"
, sort = F)
cor(df.a.b.merge$hat.x, df.a.b.merge$hat.y)
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend_7_models.csv')
df.a.b.merge <- merge(a
, b
, by = "job_id"
, sort = F)
cor(df.a.b.merge$hat.x, df.a.b.merge$hat.y)
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend_8_models.csv')
df.a.b.merge <- merge(a
, b
, by = "job_id"
, sort = F)
cor(df.a.b.merge$hat.x, df.a.b.merge$hat.y)
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend_8_models.csv')
df.a.b.merge <- merge(a
, b
, by = "job_id"
, sort = F)
cor(df.a.b.merge$hat.x, df.a.b.merge$hat.y)
job_id <- df.a.b.merge$job_id
hat <- 0.6 * df.a.b.merge$hat.x + 0.4 * df.a.b.merge$hat.y
submit <- data.table(job_id = job_id, hat = hat)
write.csv(submit, file = '../pred_final/noah_ivan_0.6_0.4_by_colmn.csv', row.names = F, quote = F)
0.7/6
a <- read.csv('../pred/submissions_20160501_unigram_full_idf_salary_geo.csv')
b <- read.csv('../pred/submissions_20160502_bigram_full_idf_salary_geo.csv')
c <- read.csv('../pred/submissions_20160505_0.986796.csv')
d <- read.csv('../pred/submissions_20160505_0.987314.csv')
e <- read.csv('../pred/submit_20160505_0.1_fix2_0.986502.csv')
f <- read.csv('../pred/submit_20160505_0.1_fix2_0.989216.csv')
g <- read.csv('../pred/submit_20160505_0.2_fix2_0.986292.csv')
h <- read.csv('../pred/submit_20160505_0.2_bytree_3.40pm.csv')
pred <- a
pred$hat <- 0.15 * a$hat +
0.65/6 * b$hat +
0.65/6 * c$hat +
0.65/6 * d$hat +
0.65/6 * e$hat +
0.65/6 * f$hat +
0.65/6 * g$hat +
0.20 * h$hat
0.65/6
cor(h$hat,pred$hat)
write.csv(pred, file = '../blend/submit_20160505_blend_8_models.csv', row.names = F)
a <- read.csv('../blend/12_10_xgb_on_all_train_md_20_salary_location_all_1_and_2_gram.csv')
b <- read.csv('../blend/submit_20160505_blend_8_models.csv')
df.a.b.merge <- merge(a
, b
, by = "job_id"
, sort = F)
cor(df.a.b.merge$hat.x, df.a.b.merge$hat.y)
job_id <- df.a.b.merge$job_id
hat <- 0.6 * df.a.b.merge$hat.x + 0.4 * df.a.b.merge$hat.y
submit <- data.table(job_id = job_id, hat = hat)
write.csv(submit, file = '../pred_final/noah_ivan_0.6_0.4_by_colmn.csv', row.names = F, quote = F)
